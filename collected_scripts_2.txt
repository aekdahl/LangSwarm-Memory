# Total Document Length: 33597 characters


--------------------------------------------------------------------------------
File: hybrid_memory.py
--------------------------------------------------------------------------------

from .base import SharedMemoryBase

class HybridSharedMemory(SharedMemoryBase):
    """
    Hybrid memory combines in-memory caching with a persistent backend.
    """

    def __init__(self, cache, backend):
        self.cache = cache
        self.backend = backend

    def write_scope(self, value, metadata=None, context_id=None):
        """
        Write a value to both in-memory and persistent backends with metadata for agent, group, and context scoping.

        Parameters:
        - value (str): Value to store.
        - metadata (dict): Metadata containing `agent_id` and `group_id`.
        - context_id (str): Context ID for grouping entries.
        """
        self.cache.write_scope(value, metadata, context_id)
        self.backend.write_scope(value, metadata, context_id)

    def read_scope(self, agent_id=None, group_id=None, context_id=None):
        """
        Read memory scoped to a specific agent, group, or context from both in-memory and persistent backends.

        Parameters:
        - agent_id (str): ID of the agent requesting the scope.
        - group_id (str): ID of the group requesting the scope.
        - context_id (str, optional): Restrict results to a specific context.

        Returns:
        - Dictionary of key-value pairs visible to the agent or group within the context.
        """
        # Read scoped data from in-memory and persistent backends
        in_memory_data = self.cache.read_scope(agent_id, group_id, context_id)
        persistent_data = self.backend.read_scope(agent_id, group_id, context_id)

        # Merge and prioritize in-memory data
        combined_data = {**persistent_data, **in_memory_data}
        return combined_data
        
    def read(self, key=None):
        # Try reading from cache first
        value = self.cache.read(key)
        if value is not None:
            return value

        # Fallback to backend if not found in cache
        value = self.backend.read(key)
        if value is not None:
            self.cache.write(key, value)  # Cache the result
        return value

    def write(self, key, value):
        self.cache.write(key, value)
        self.backend.write(key, value)

    def delete(self, key):
        self.cache.delete(key)
        self.backend.delete(key)

    def clear(self):
        self.cache.clear()
        self.backend.clear()



--------------------------------------------------------------------------------
File: chromadb_memory.py
--------------------------------------------------------------------------------

from chromadb import Client
from chromadb.config import Settings
import asyncio
from threading import Lock
from datetime import datetime

from chromadb import Client
from chromadb.config import Settings
from datetime import datetime
import asyncio
from threading import Lock


class ChromaDBSharedMemory:
    """
    ChromaDB-backed shared memory with optional thread-safe and async-safe operations.
    """

    def __init__(self, collection_name="shared_memory", persist_directory=None, thread_safe=True, async_safe=False):
        """
        Initialize ChromaDB client and thread/async locks.

        Parameters:
        - collection_name (str): Name of the ChromaDB collection.
        - persist_directory (str): Directory for ChromaDB persistence.
        - thread_safe (bool): Enable thread-safe operations.
        - async_safe (bool): Enable async-safe operations.
        """
        self.client = Client(Settings(persist_directory=persist_directory))
        self.collection = self.client.get_or_create_collection(name=collection_name)
        self.thread_safe = thread_safe or async_safe

        if self.thread_safe:
            self.lock = asyncio.Lock() if async_safe else Lock()

    def _generate_entry_id(self, context_id):
        """
        Generate a unique ID for an entry using context_id and timestamp.
        """
        timestamp = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        return f"{context_id}:{timestamp}"

    def _get_default_metadata(self, metadata):
        now = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        return {
            "agent": metadata.get("agent"),
            "timestamp": metadata.get("timestamp", now),
            "llm": metadata.get("llm"),
            "action": metadata.get("action"),
            "confidence": metadata.get("confidence"),
            "query": metadata.get("query"),
        }

    def write_scope(self, value, metadata=None, context_id=None):
        """
        Write a value to ChromaDB with metadata for agent, group, and context scoping.

        Parameters:
        - value (str): Value to store.
        - metadata (dict): Metadata containing `agent_id` and `group_id`.
        - context_id (str): Context ID for grouping entries.
        """
        metadata = metadata or {}
        entry_id = self._generate_entry_id(context_id)
        entry_metadata = {
            "context_id": context_id,
            "agent_id": metadata.get("agent_id"),
            "group_id": metadata.get("group_id"),
            "timestamp": entry_id.split(":")[1],  # Extract timestamp from the ID
            **metadata,
        }

        def _write():
            self.collection.add(ids=[entry_id], documents=[value], metadatas=[entry_metadata])

        if self.thread_safe:
            with self.lock:
                _write()
        else:
            _write()

    def read_scope(self, agent_id=None, group_id=None, context_id=None):
        """
        Read memory scoped to a specific agent, group, or context.

        Parameters:
        - agent_id (str): ID of the agent requesting the scope.
        - group_id (str): ID of the group requesting the scope.
        - context_id (str, optional): Restrict results to a specific context.

        Returns:
        - Dictionary of key-value pairs visible to the agent or group within the context.
        """
        def _read():
            query_filter = {}
            if context_id:
                query_filter["context_id"] = context_id
            if agent_id:
                query_filter["agent_id"] = agent_id
            if group_id:
                query_filter["group_id"] = group_id

            results = self.collection.get(where=query_filter, sort_by="timestamp", sort_order="asc")
            return {
                result_id: {
                    "value": document,
                    "metadata": metadata,
                }
                for result_id, document, metadata in zip(results["ids"], results["documents"], results["metadatas"])
            }

        if self.thread_safe:
            with self.lock:
                return _read()
        else:
            return _read()

    def read_context(self, context_id):
        """
        Read all entries for a given context_id, ordered by timestamp.

        Parameters:
        - context_id (str): The context ID to fetch.

        Returns:
        - Ordered dictionary of key-value pairs.
        """
        def _read():
            results = self.collection.get(
                where={"context_id": context_id},
                sort_by="timestamp",
                sort_order="asc"
            )
            return {
                result_id: {
                    "value": document,
                    "metadata": metadata
                }
                for result_id, document, metadata in zip(results["ids"], results["documents"], results["metadatas"])
            }

        if self.thread_safe:
            with self.lock:
                return _read()
        else:
            return _read()

    def write(self, value, metadata=None, context_id=None):
        """
        Write a value to ChromaDB with metadata and context_id.

        Parameters:
        - value (str): Value to store.
        - metadata (dict): Optional metadata.
        - context_id (str): Context ID for grouping entries.
        """
        metadata = metadata or {}
        entry_id = self._generate_entry_id(context_id)
        entry_metadata = {
            **metadata,
            "context_id": context_id,
            "timestamp": entry_id.split(":")[1],  # Extract timestamp from the ID
        }

        def _write():
            self.collection.add(ids=[entry_id], documents=[value], metadatas=[entry_metadata])

        if self.thread_safe:
            with self.lock:
                _write()
        else:
            _write()

    def delete_context(self, context_id):
        """
        Delete all entries for a given context_id.

        Parameters:
        - context_id (str): The context ID to delete.
        """
        def _delete():
            self.collection.delete(where={"context_id": context_id})

        if self.thread_safe:
            with self.lock:
                _delete()
        else:
            _delete()

    def clear(self):
        """
        Clear all entries in the ChromaDB collection.
        """
        def _clear():
            self.collection.delete()

        if self.thread_safe:
            with self.lock:
                _clear()
        else:
            _clear()

    def similarity_search(self, query, top_k=5):
        """
        Perform similarity search in ChromaDB.

        Parameters:
        - query (str): Query string to search.
        - top_k (int): Number of top similar results to return.

        Returns:
        - List of top_k most similar documents.
        """
        def _search():
            query_vector = self.client.encode(query)
            results = self.collection.query(query_embeddings=[query_vector], n_results=top_k)
            return results["documents"]

        if self.thread_safe:
            with self.lock:
                return _search()
        else:
            return _search()



--------------------------------------------------------------------------------
File: in_memory.py
--------------------------------------------------------------------------------

from .base import SharedMemoryBase

try:
    from sklearn.metrics.pairwise import cosine_similarity
    from sentence_transformers import SentenceTransformer
except ImportError:
    cosine_similarity = None
    SentenceTransformer = None

import asyncio
from threading import Lock
from datetime import datetime


class InMemorySharedMemory(SharedMemoryBase):
    """
    A basic in-memory implementation of shared memory.
    """

    def __init__(self, thread_safe = True, async_safe = False):
        self.memory = {}
        self.thread_safe = thread_safe or async_safe
        
        if self.thread_safe:
            if async_safe:
                self.lock = asyncio.Lock()
            else:
                self.lock = Lock()

        if SentenceTransformer:
            self.model = SentenceTransformer("all-MiniLM-L6-v2")
            self.embeddings = {}

    def _get_default_metadata(self, metadata):
        now = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        return {
            "agent": metadata.get("agent"),
            "timestamp": metadata.get("timestamp", now),
            "llm": metadata.get("llm"),
            "action": metadata.get("action"),
            "confidence": metadata.get("confidence"),
            "query": metadata.get("query"),
        }

    def read_scope(self, agent_id=None, group_id=None, context_id=None):
        """
        Read memory entries scoped to a specific agent, group, or context.
        """
        def _filter_scope():
            result = {}
            for key, entry in self.memory.items():
                metadata = entry.get("metadata", {})
                if context_id and not key.startswith(f"{context_id}:"):
                    continue  # Skip entries not in the specified context
                if agent_id and metadata.get("agent_id") == agent_id:
                    result[key] = entry
                elif group_id and metadata.get("group_id") == group_id:
                    result[key] = entry
            return result
    
        if self.thread_safe:
            with self.lock:
                return _filter_scope()
        else:
            return _filter_scope()

    def write_scope(self, value, metadata=None, context_id=None):
        metadata = metadata or {}
        timestamp = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        key = f"{context_id}:{timestamp}"
        entry_metadata = {
            "agent_id": metadata.get("agent_id"),
            "group_id": metadata.get("group_id"),
            "timestamp": timestamp,
            **metadata,
        }
        entry = {"value": value, "metadata": entry_metadata}

        if self.thread_safe:
            with self.lock:
                self.memory[key] = entry
        else:
            self.memory[key] = entry

    def read_context(self, context_id):
        """
        Read all entries for a given context_id in timestamp order.
        """
        def _read():
            return {
                key: value
                for key, value in sorted(self.memory.items())
                if key.startswith(f"{context_id}:")
            }

        if self.thread_safe:
            with self.lock:
                return _read()
        else:
            return _read()

    def write(self, value, metadata=None, context_id=None):
        metadata = metadata or {}
        timestamp = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        key = f"{context_id}:{timestamp}"
        entry = {"value": value, "metadata": self._get_default_metadata(metadata)}

        if self.thread_safe:
            with self.lock:
                self.memory[key] = entry
        else:
            self.memory[key] = entry
            
    def delete(self, key):
        """
        Delete a specific key from memory.
        """
        if self.thread_safe:
            with self.lock:
                if key in self.memory:
                    del self.memory[key]
        else:
            if key in self.memory:
                del self.memory[key]
                
    def clear(self):
        """
        Clear all memory.
        """
        if self.thread_safe:
            with self.lock:
                self.memory.clear()
        else:
            self.memory.clear()
            
    def similarity_search(self, query, top_k=5):
        if cosine_similarity is not None and SentenceTransformer is ot None:
            query_vector = self.model.encode(query)
            similarities = {
                key: cosine_similarity([query_vector], [vector])[0][0]
                for key, vector in self.embeddings.items()
            }
            sorted_keys = sorted(similarities, key=similarities.get, reverse=True)
            return [(key, similarities[key]) for key in sorted_keys[:top_k]]
        else:
            return []



--------------------------------------------------------------------------------
File: sqlite_memory.py
--------------------------------------------------------------------------------

import sqlite3
import asyncio
from datetime import datetime
from .base import SharedMemoryBase


class SQLiteSharedMemory(SharedMemoryBase):
    """
    SQLite-backed shared memory with optional thread-safe and async-safe operations.
    """

    def __init__(self, db_path=":memory:", thread_safe=True, async_safe=False):
        """
        Initialize SQLite database and thread/async locks.

        Parameters:
        - db_path (str): Path to the SQLite database file. Defaults to in-memory.
        - thread_safe (bool): Enable thread-safe operations.
        - async_safe (bool): Enable async-safe operations.
        """
        self.db_path = db_path
        self.thread_safe = thread_safe or async_safe

        if self.thread_safe:
            self.lock = asyncio.Lock() if async_safe else Lock()

        self._initialize_db()

    def _initialize_db(self):
        """
        Initialize the SQLite database schema.
        """
        with self._get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS memory (
                    key TEXT PRIMARY KEY,
                    value TEXT NOT NULL,
                    metadata TEXT
                )
            """)
            conn.commit()

    def _get_connection(self):
        """
        Get a new SQLite connection.
        """
        return sqlite3.connect(self.db_path)

    def _get_default_metadata(self, metadata):
        now = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        return {
            "agent": metadata.get("agent"),
            "timestamp": metadata.get("timestamp", now),
            "llm": metadata.get("llm"),
            "action": metadata.get("action"),
            "confidence": metadata.get("confidence"),
            "query": metadata.get("query"),
        }

    def read_scope(self, agent_id=None, group_id=None, context_id=None):
        """
        Read memory entries scoped to a specific agent, group, or context.
        """
        def _filter_scope():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                query = "SELECT key, value, metadata FROM memory WHERE 1=1"
                params = []
    
                if context_id:
                    query += " AND key LIKE ?"
                    params.append(f"{context_id}:%")
                if agent_id:
                    query += " AND metadata LIKE ?"
                    params.append(f'%\"agent_id\": \"{agent_id}\"%')
                if group_id:
                    query += " AND metadata LIKE ?"
                    params.append(f'%\"group_id\": \"{group_id}\"%')
    
                cursor.execute(query, params)
                rows = cursor.fetchall()
                result = {
                    row[0]: {"value": row[1], "metadata": eval(row[2])}
                    for row in rows
                }
                return result
    
        if self.thread_safe:
            with self.lock:
                return _filter_scope()
        else:
            return _filter_scope()

    def write_scope(self, value, metadata=None, context_id=None):
        metadata = metadata or {}
        timestamp = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        key = f"{context_id}:{timestamp}"
        entry_metadata = str({
            "agent_id": metadata.get("agent_id"),
            "group_id": metadata.get("group_id"),
            "timestamp": timestamp,
            **metadata,
        })

        def _write():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT OR REPLACE INTO memory (key, value, metadata)
                    VALUES (?, ?, ?)
                """, (key, value, entry_metadata))
                conn.commit()

        if self.thread_safe:
            with self.lock:
                _write()
        else:
            _write()

    def read_context(self, context_id):
        """
        Read all entries for a given context_id in timestamp order.
        """
        def _read():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT key, value, metadata FROM memory WHERE key LIKE ? ORDER BY key", (f"{context_id}:%",))
                rows = cursor.fetchall()
                return {
                    row[0]: {"value": row[1], "metadata": eval(row[2])}
                    for row in rows
                }

        if self.thread_safe:
            with self.lock:
                return _read()
        else:
            return _read()

    def write(self, value, metadata=None, context_id=None):
        metadata = metadata or {}
        timestamp = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        key = f"{context_id}:{timestamp}"
        entry_metadata = str(self._get_default_metadata(metadata))

        def _write():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT OR REPLACE INTO memory (key, value, metadata)
                    VALUES (?, ?, ?)
                """, (key, value, entry_metadata))
                conn.commit()

        if self.thread_safe:
            with self.lock:
                _write()
        else:
            _write()

    def delete(self, key):
        """
        Delete a key in SQLite.

        Parameters:
        - key (str): Key to delete.
        """
        def _delete():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("DELETE FROM memory WHERE key = ?", (key,))
                conn.commit()

        if self.thread_safe:
            with self.lock:
                _delete()
        else:
            _delete()

    def clear(self):
        """
        Clear all entries in SQLite.
        """
        def _clear():
            with self._get_connection() as conn:
                cursor = conn.cursor()
                cursor.execute("DELETE FROM memory")
                conn.commit()

        if self.thread_safe:
            with self.lock:
                _clear()
        else:
            _clear()



--------------------------------------------------------------------------------
File: __init__.py
--------------------------------------------------------------------------------





--------------------------------------------------------------------------------
File: utils.py
--------------------------------------------------------------------------------





--------------------------------------------------------------------------------
File: base.py
--------------------------------------------------------------------------------

from abc import ABC, abstractmethod

class SharedMemoryBase(ABC):
    """
    Abstract base class for shared memory implementations.
    """
    
    @abstractmethod
    def read_scope(self, agent_id=None, group_id=None, context_id=None):
        """
        Read memory scoped to a specific agent, group, or context.

        Parameters:
        - agent_id (str): ID of the agent requesting the scope.
        - group_id (str): ID of the group requesting the scope.
        - context_id (str, optional): Restrict results to a specific context.

        Returns:
        - Filtered dictionary of key-value pairs visible to the agent or group within the context.
        """
        pass

    @abstractmethod
    def write_scope(self, value, metadata=None, context_id=None):
        """
        Write a value to memory with metadata for agent, group, or context scoping.

        Parameters:
        - value (str): Value to store.
        - metadata (dict): Metadata containing `agent_id` and `group_id`.
        - context_id (str): Context ID for grouping entries.
        """
        pass

    @abstractmethod
    def read(self, key=None, context_id=None):
        """
        Read memory. If context_id is provided, fetch all entries in the context.

        Parameters:
        - key: Specific key to fetch (optional).
        - context_id: Fetch all entries in the given context (optional).
        """
        pass

    @abstractmethod
    def write(self, key, value, metadata=None, context_id=None):
        """
        Write a key-value pair to memory with metadata and context_id.

        Parameters:
        - key (str): Key to store.
        - value (str): Value to store.
        - metadata (dict, optional): Metadata about the entry. Fields:
          - agent (str): Agent identifier.
          - timestamp (str): ISO 8601 timestamp (default: now).
          - llm (str): Optional LLM used.
          - action (str): Optional action type (e.g., query, response).
          - confidence (float): Optional confidence score.
          - query (str): Optional original query leading to this entry.
        - context_id: ID of the context (optional).
        """
        pass

    @abstractmethod
    def delete(self, key):
        """Delete a specific key from memory."""
        pass

    @abstractmethod
    def clear(self):
        """Clear all memory."""
        pass

    @abstractmethod
    def similarity_search(self, query, top_k=5):
        """
        Perform similarity search on stored data.

        Parameters:
        - query (str): Query string to search.
        - top_k (int): Number of top similar results to return.

        Returns:
        - List of most similar documents.
        """
        raise NotImplementedError("Similarity search is not supported for this backend.")




--------------------------------------------------------------------------------
File: gcs_memory.py
--------------------------------------------------------------------------------

from google.cloud import storage
import asyncio
from datetime import datetime
from .base import SharedMemoryBase


class GCSSharedMemory(SharedMemoryBase):
    """
    Google Cloud Storage (GCS)-backed shared memory with optional thread-safe and async-safe operations.
    """

    def __init__(self, bucket_name, prefix="shared_memory/", thread_safe=True, async_safe=False):
        """
        Initialize GCS client and thread/async locks.

        Parameters:
        - bucket_name (str): GCS bucket name.
        - prefix (str): Prefix for keys in the bucket.
        - thread_safe (bool): Enable thread-safe operations.
        - async_safe (bool): Enable async-safe operations.
        """
        self.client = storage.Client()
        self.bucket = self.client.bucket(bucket_name)
        self.prefix = prefix
        self.thread_safe = thread_safe or async_safe

        if self.thread_safe:
            if async_safe:
                self.lock = asyncio.Lock()
            else:
                self.lock = Lock()

    def _get_blob(self, key):
        return self.bucket.blob(f"{self.prefix}{key}")

    def _get_default_metadata(self, metadata):
        now = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        return {
            "agent": metadata.get("agent"),
            "timestamp": metadata.get("timestamp", now),
            "llm": metadata.get("llm"),
            "action": metadata.get("action"),
            "confidence": metadata.get("confidence"),
            "query": metadata.get("query"),
        }

    def read_scope(self, agent_id=None, group_id=None, context_id=None):
        """
        Read memory entries scoped to a specific agent, group, or context.
        """
        def _filter_scope():
            blobs = sorted(self.client.list_blobs(self.bucket, prefix=f"{self.prefix}{context_id}:" if context_id else self.prefix))
            result = {}
            for blob in blobs:
                entry = eval(blob.download_as_text())
                metadata = entry.get("metadata", {})
                if agent_id and metadata.get("agent_id") == agent_id:
                    result[blob.name[len(self.prefix):]] = entry
                elif group_id and metadata.get("group_id") == group_id:
                    result[blob.name[len(self.prefix):]] = entry
            return result
    
        if self.thread_safe:
            with self.lock:
                return _filter_scope()
        else:
            return _filter_scope()

    def write_scope(self, value, metadata=None, context_id=None):
        metadata = metadata or {}
        timestamp = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        key = f"{context_id}:{timestamp}"
        entry_metadata = {
            "agent_id": metadata.get("agent_id"),
            "group_id": metadata.get("group_id"),
            "timestamp": timestamp,
            **metadata,
        }
        entry = {"value": value, "metadata": entry_metadata}

        def _write():
            blob = self._get_blob(key)
            blob.upload_from_string(str(entry))

        if self.thread_safe:
            with self.lock:
                _write()
        else:
            _write()

    def read_context(self, context_id):
        """
        Read all entries for a given context_id in timestamp order.
        """
        def _read():
            blobs = sorted(self.client.list_blobs(self.bucket, prefix=f"{self.prefix}{context_id}:"))
            return {
                blob.name[len(self.prefix):]: eval(blob.download_as_text())
                for blob in blobs
            }

        if self.thread_safe:
            with self.lock:
                return _read()
        else:
            return _read()

    def write(self, value, metadata=None, context_id=None):
        metadata = metadata or {}
        timestamp = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        key = f"{context_id}:{timestamp}"
        entry = {"value": value, "metadata": self._get_default_metadata(metadata)}

        def _write():
            blob = self._get_blob(key)
            blob.upload_from_string(str(entry))

        if self.thread_safe:
            with self.lock:
                _write()
        else:
            _write()

    def delete(self, key):
        """
        Delete a key in GCS.
        """
        def _delete():
            blob = self._get_blob(key)
            if blob.exists():
                blob.delete()

        if self.thread_safe:
            with self.lock:
                _delete()
        else:
            _delete()

    def clear(self):
        """
        Clear all keys in GCS.
        """
        def _clear():
            blobs = self.client.list_blobs(self.bucket, prefix=self.prefix)
            for blob in blobs:
                blob.delete()

        if self.thread_safe:
            with self.lock:
                _clear()
        else:
            _clear()



--------------------------------------------------------------------------------
File: redis_memory.py
--------------------------------------------------------------------------------

import redis
import asyncio
from datetime import datetime
from .base import SharedMemoryBase


class RedisSharedMemory(SharedMemoryBase):
    """
    Redis-backed shared memory with optional thread-safe and async-safe operations.
    """

    def __init__(self, redis_url="redis://localhost:6379/0", thread_safe=True, async_safe=False):
        """
        Initialize Redis client and thread/async locks.

        Parameters:
        - redis_url (str): Redis connection URL.
        - thread_safe (bool): Enable thread-safe operations.
        - async_safe (bool): Enable async-safe operations.
        """
        self.client = redis.StrictRedis.from_url(redis_url)
        self.thread_safe = thread_safe or async_safe

        if self.thread_safe:
            if async_safe:
                self.lock = asyncio.Lock()
            else:
                self.lock = Lock()

    def _get_default_metadata(self, metadata):
        now = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        return {
            "agent": metadata.get("agent"),
            "timestamp": metadata.get("timestamp", now),
            "llm": metadata.get("llm"),
            "action": metadata.get("action"),
            "confidence": metadata.get("confidence"),
            "query": metadata.get("query"),
        }

    def read_scope(self, agent_id=None, group_id=None, context_id=None):
        """
        Read memory entries scoped to a specific agent, group, or context.
        """
        def _filter_scope():
            keys = self.client.keys(f"{context_id}:*" if context_id else "*")
            result = {}
            for key in sorted(keys):  # Ensure lexicographical order
                entry = eval(self.client.get(key).decode())
                metadata = entry.get("metadata", {})
                if agent_id and metadata.get("agent_id") == agent_id:
                    result[key.decode()] = entry
                elif group_id and metadata.get("group_id") == group_id:
                    result[key.decode()] = entry
            return result
    
        if self.thread_safe:
            with self.lock:
                return _filter_scope()
        else:
            return _filter_scope()

    def write_scope(self, value, metadata=None, context_id=None):
        metadata = metadata or {}
        timestamp = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        key = f"{context_id}:{timestamp}"
        entry_metadata = {
            "agent_id": metadata.get("agent_id"),
            "group_id": metadata.get("group_id"),
            "timestamp": timestamp,
            **metadata,
        }
        entry = {"value": value, "metadata": entry_metadata}

        def _write():
            self.client.set(key, str(entry))

        if self.thread_safe:
            with self.lock:
                _write()
        else:
            _write()

    def read_context(self, context_id):
        """
        Read all entries for a given context_id in timestamp order.
        """
        def _read():
            keys = sorted(self.client.keys(f"{context_id}:*"))
            return {
                key.decode(): eval(self.client.get(key).decode())
                for key in keys
            }

        if self.thread_safe:
            with self.lock:
                return _read()
        else:
            return _read()

    def write(self, value, metadata=None, context_id=None):
        metadata = metadata or {}
        timestamp = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")
        key = f"{context_id}:{timestamp}"
        entry = {"value": value, "metadata": self._get_default_metadata(metadata)}

        def _write():
            self.client.set(key, str(entry))

        if self.thread_safe:
            with self.lock:
                _write()
        else:
            _write()

    def delete(self, key):
        """
        Delete a key in Redis.
        """
        def _delete():
            self.client.delete(key)

        if self.thread_safe:
            with self.lock:
                _delete()
        else:
            _delete()

    def clear(self):
        """
        Clear all keys in Redis.
        """
        def _clear():
            self.client.flushdb()

        if self.thread_safe:
            with self.lock:
                _clear()
        else:
            _clear()



--------------------------------------------------------------------------------
File: integrations/__init__.py
--------------------------------------------------------------------------------





--------------------------------------------------------------------------------
File: integrations/langswarm.py
--------------------------------------------------------------------------------

from memswarm import InMemorySharedMemory, RedisSharedMemory

class LangSwarmIntegration:
    """
    A utility for integrating MemSwarm with LangSwarm workflows.
    """

    @staticmethod
    def setup_shared_memory(agent_wrappers, memory_type="in_memory", **kwargs):
        """
        Setup shared memory for a list of LangSwarm AgentWrapper instances.

        Parameters:
        - agent_wrappers: List of AgentWrapper instances.
        - memory_type: Type of shared memory ("in_memory" or "redis").
        - kwargs: Additional parameters for the memory implementation.
        """
        if memory_type == "in_memory":
            shared_memory = InMemorySharedMemory()
        elif memory_type == "redis":
            shared_memory = RedisSharedMemory(**kwargs)
        else:
            raise ValueError(f"Unsupported memory type: {memory_type}")

        for agent in agent_wrappers:
            agent.shared_memory = shared_memory


